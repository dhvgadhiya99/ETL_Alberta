In this project, we performed an Extract, Transform, Load (ETL) process on address data sourced from the Statistics Canada Open Database of Addresses. The data, extracted from an Excel sheet, pertained specifically to Alberta, Canada, containing 1,777,428 rows and 22 columns. Through Python scripting and SQL Server Management Studio, we normalized the street names and city names to facilitate precise geospatial analysis and enhance the accuracy of future insights.

The normalization of street names was crucial for consistent and accurate analysis, enabling tasks such as mapping locations, calculating distances, and analyzing patterns based on geographic location within the city. By standardizing the data, we ensured its readiness for visualization and further analysis.

This ETL process not only transformed raw data into a structured format but also laid the groundwork for future analysis and decision-making. With the normalized dataset, possibilities for visual insights using tools like Power BI or Tableau emerge, enabling applications such as city planning, demographic analysis, urban planning, and market strategies.

Through this project, we learned the importance of time management in handling large datasets and the significance of collaborative group work in completing such projects effectively and efficiently.

Overall, the ETL process demonstrated its value in increasing data quality, streamlining workflows, and providing valuable information for enterprises and decision-makers.
